{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "from datetime import datetime\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import dask.dataframe as dd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://archive.luftdaten.info'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_link(link):\n",
    "    try:\n",
    "        datetime.strptime(link['href'][0:-1], '%Y-%m-%d')\n",
    "    except ValueError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "    \n",
    "def get_file_links(link):\n",
    "    soup = BeautifulSoup(requests.get(link). content, 'html.parser')\n",
    "    links = soup.findAll('a')\n",
    "    return [link + l['href'] for l in links if '.csv' in l['href']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all csv link in on list\n",
    "\n",
    "links = [link['href'] for link in soup.findAll('a') if valid_link(link)]\n",
    "links = [url + '/'+ link for link in links]\n",
    "links = [get_file_links(link) for link in links]\n",
    "links = list(chain.from_iterable(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_for_sensor = {'bme280': [], 'sds011':[], 'dht22':[], 'none': []}\n",
    "\n",
    "def sort_in(d, link):\n",
    "    if 'bme280' in link:\n",
    "        d['bme280'].append(link)\n",
    "    elif 'sds011' in link:\n",
    "        d['sds011'].append(link)\n",
    "    elif 'dht22' in link:\n",
    "        d['dht22'].append(link)\n",
    "    else:\n",
    "        d['none'].append(link)\n",
    "    return d\n",
    "        \n",
    "\n",
    "#Divide links into sensor types\n",
    "links_for_sensor = reduce(sort_in, links,links_for_sensor)\n",
    "\n",
    "print('Link count for sensor type')\n",
    "len(links_for_sensor['bme280']), len(links_for_sensor['sds011']), len(links_for_sensor['dht22']), len(links_for_sensor['none'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'links_for_sensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-73312afad124>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Check single CSV' for incon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msensor_typ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlinks_for_sensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensor_typ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#c = d6tstack.combine_csv.CombinerCSV(links_for_sensor['bme280'][0:10], sep=';')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'links_for_sensor' is not defined"
     ]
    }
   ],
   "source": [
    "#Check single CSV' for incon\n",
    "\n",
    "for sensor_typ in ['bme280', 'sds011', 'dht22']:\n",
    "    c = d6tstack.combine_csv.CombinerCSV(links_for_sensor[sensor_typ], sep=';')\n",
    "    c.to_mysql_combine('mysql+mysqlconnector://root:example@localhost:3306/btw', sensor_typ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql\n",
    "config = {\n",
    "        'user': 'root',\n",
    "        'password': 'example',\n",
    "        'host': 'localhost',\n",
    "        'port': '3306',\n",
    "        'database': 'btw'\n",
    "    }\n",
    "connection = mysql.connector.connect(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mysql.connector.connection.MySQLConnection at 0x14ffb8400>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##df = reduce(lambda df,link: df.append(pd.read_csv(link, sep=';'), sort=False), tqdm(links_for_sensor['bme280'][0:10]), pd.DataFrame())\n",
    "##df = dd.read_csv(links_for_sensor['bme280'][0:5], sep=';').compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BTW",
   "language": "python",
   "name": "btw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
